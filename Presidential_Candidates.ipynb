{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Presidential_Candidates.ipynb","provenance":[],"authorship_tag":"ABX9TyNMA2mXHL8SaQQXwG+WufFZ"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"_wR0iGIA9kxm","colab_type":"code","outputId":"15ea83c3-48ca-4963-81a4-75d9c2d2877c","executionInfo":{"status":"ok","timestamp":1587131141971,"user_tz":360,"elapsed":29216,"user":{"displayName":"Elijah Cox","photoUrl":"","userId":"12779208509741799141"}},"colab":{"base_uri":"https://localhost:8080/","height":309}},"source":["import os\n","import re\n","import csv\n","import string\n","import gensim\n","import json\n","import pandas\n","import urllib.parse\n","import requests\n","import statistics\n","from bs4 import BeautifulSoup as bs\n","from gensim import corpora\n","import nltk\n","nltk.download('vader_lexicon')\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","from nltk.corpus import stopwords \n","from nltk.stem.wordnet import WordNetLemmatizer\n","from nltk.sentiment.vader import SentimentIntensityAnalyzer\n","!pip install fa2"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/wordnet.zip.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n","  warnings.warn(\"The twython library has not been installed. \"\n"],"name":"stderr"},{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /gdrive\n","Requirement already satisfied: fa2 in /usr/local/lib/python3.6/dist-packages (0.3.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from fa2) (1.4.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from fa2) (4.38.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fa2) (1.18.2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9BS7nPYpIGsM","colab_type":"code","colab":{}},"source":["def to_text(pathway):    \n","  with open(pathway) as infile:        \n","    return infile.read()\n","def clean(doc):   \n","  stop = set(stopwords.words('english'))\n","  exclude = set(string.punctuation) \n","  lemma = WordNetLemmatizer() \n","  stop_free = \" \".join([i for i in doc.lower().split() if i not in stop])    \n","  punc_free = ''.join(ch for ch in stop_free if ch not in exclude)    \n","  normalized = \" \".join(lemma.lemmatize(word) for word in punc_free.split())    \n","  return normalized"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"F8mRYmDrt2Uf","colab_type":"code","colab":{}},"source":["def create_corpus(site, corpus_folder=Corpus_dir):  # This function is Lab 9.\n","  '''Starting with the given site, navigates to external links and harvests text to create a corpus, saved as various .txt files in the corpus folder.'''\n","  \n","  os.chdir(corpus_folder)\n","  webpage = requests.get(site)\n","  soup = bs(webpage.text, \"html.parser\")\n","\n","  # Find all <a> tags in the html \n","  tags = soup.find_all('a')\n","\n","  # Find the links by getting the href= attribute on each tag and append them to a list\n","  links = [tag.get('href') for tag in tags if tag.get('href') != None and 'http' in tag.get('href')] #Optional condition to filter links\n","  for i, link in enumerate(links):\n","    #if i < 10: #Change this condition; it should have to do with the length of the text string\n","    webpage = requests.get(link)\n","    soup = bs(webpage.text, \"html.parser\")\n","    paragraphs = soup.find_all('p')\n","    if len(paragraphs) > 2:\n","      # Write the text from the link to a file with the appropriate name\n","      with open(f'link_{i}.txt', mode = 'w') as fout:\n","        #fout.write(soup.get_text())\n","        fout.write(urllib.parse.urlparse(site).netloc + '\\n')    \n","        for i in paragraphs:        \n","          fout.write(i.get_text() + '\\n')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SUy0Oj6aGdp8","colab_type":"code","colab":{}},"source":["def topic_model(corpus_loc, n_topics = 10, destination = None,candidate_n=None):\n","  '''Creates a .csv file with one topic from the corpus per column and saves it to destination.'''\n","  os.chdir(corpus_loc)\n","  \n","  # Create a list of all files in the corpus                                \n","  filenames = [i for i in os.listdir() if re.search(r\"\\.txt\", i)] \n","  doc_complete = [to_text(i) for i in filenames]\n","\n","  # Remove punctuation and stopwords from the files\n","  stop = set(stopwords.words('english'))\n","  exclude = set(string.punctuation) \n","  lemma = WordNetLemmatizer()\n","  doc_clean = [clean(doc).split() for doc in doc_complete]  \n","\n","  # Set the number of topics                                                \n","  num_topics = n_topics\n","\n","  # Convert the list of documents (corpus) into Document Term Matrix using a dictionary\n","  dictionary = corpora.Dictionary(doc_clean)\n","  doc_term_matrix = [dictionary.doc2bow(doc) for doc in doc_clean]\n","\n","  # Create the object for LDA model using gensim library\n","  Lda = gensim.models.ldamodel.LdaModel\n","  ldamodel = Lda(doc_term_matrix, num_topics=num_topics, id2word = dictionary, passes=50)\n","  output = ldamodel.print_topics(num_topics=num_topics, num_words=8)         \n","\n","  # Format the data\n","  columns = [[]]*len(output)\n","  for i in range(len(output)):\n","    columns[i] = re.findall(r'\\\"\\w+\\\"', output[i][1])\n","    columns[i].insert(0,i+1)\n","  # for k in columns:\n","  #   print(k)                                                           \n","  \n","  # Export the results to a .csv file\n","  if destination != None:\n","    os.chdir(destination)\n","    with open(f'{candidate_n}.csv', mode= 'w') as csvfile:\n","      writer = csv.writer(csvfile)\n","      for item in columns:\n","        writer.writerow(item)\n","\n","  return columns"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VwCTytx5IRzk","colab_type":"code","colab":{}},"source":["def get_sentiment(fname): #, aspect):\n","  '''Given a .txt file and a column number, calculates the aspect-based sentiment score.'''\n","  output = []\n","  with open(fname, mode='r') as infile:\n","    sid = SentimentIntensityAnalyzer()\n","    text = infile.read()\n","    return sid.polarity_scores(text)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vh8uokmBq3vB","colab_type":"code","colab":{}},"source":["def political_info(sitename, candidate_name, corpus_dir, n_topic):\n","  '''Given a campaign or other website, creates a corpus and then models the topics in it.'''\n","  os.chdir(corpus_dir)\n","  create_corpus(sitename, corpus_dir) \n","  issues = topic_model(corpus_dir, n_topics = n_topic, destination = Models_dir,candidate_n=candidate_name)\n","\n","\n","  return issues"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oJ7o8mXWR5b_","colab_type":"code","colab":{}},"source":["class candidate:\n","  # Initializer\n","  def __init__(self, name, topics):\n","    self.name = name\n","    self.topics = topics # Should be instantiated as a dictionary with issue objects as values\n","    self.topics_dict = {}\n","    for topic in topics:\n","      self.topics_dict[topic.name] = (topic.words, topic.avg_sentiment) \n","  # Methods\n","  def get_opinion(self):\n","    print(f'{self.name} has opinions on the following issues:\\n')\n","    print([topic.name for topic in self.topics],'\\n')\n","    topic_name = input('Which of these do you want to know about?\\n')\n","    try:\n","      pair = self.topics_dict[topic_name]\n","      print(f'When talking about {topic_name}, {self.name} frequently uses the following words:')\n","      for i in pair[0]:\n","        print(i, end=', ')\n","      print(f'and seems to feel {pair[1]} about it.')\n","    except KeyError as e:\n","      print('That isn\\'t one of the topics I mentioned. Check your spelling.')\n","\n","class issue:\n","  # Initializer\n","  def __init__(self, name, words = [], avg_sentiment = 0):\n","    self.name = name\n","    self.words = words\n","    self.avg_sentiment = avg_sentiment\n","  # Methods\n","  def get_words(self):\n","    return self.words\n","  def get_sentiment(self):\n","    return self.avg_sentiment"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SUrhOV_l25S3","colab_type":"code","outputId":"ed39c6f1-3389-4bb1-daa7-1a9f37caab74","executionInfo":{"status":"ok","timestamp":1587131338747,"user_tz":360,"elapsed":29909,"user":{"displayName":"Elijah Cox","photoUrl":"","userId":"12779208509741799141"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["for i in political_info(\"https://www.donaldjtrump.com/\", 'Donald Trump', '/gdrive/My Drive/LING/Final Project/Corpus files - Trump', n_topic=5):\n","  print(i)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[1, '\"coronavirus\"', '\"president\"', '\"april\"', '\"trump\"', '\"announced\"', '\"march\"', '\"new\"', '\"state\"']\n","[2, '\"trump\"', '\"committee\"', '\"president\"', '\"america\"', '\"inc\"', '\"donald\"', '\"j\"', '\"apply\"']\n","[3, '\"tweet\"', '\"twitter\"', '\"trump\"', '\"add\"', '\"president\"', '\"america\"', '\"learn\"', '\"website\"']\n","[4, '\"trump\"', '\"coronavirus\"', '\"president\"', '\"april\"', '\"march\"', '\"announced\"', '\"tweet\"', '\"twitter\"']\n","[5, '\"loading\"', '\"distancing\"', '\"protocol\"', '\"vulnerable\"', '\"adhere\"', '\"physical\"', '\"eg\"', '\"area\"']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6IPJTXCOCLs7","colab_type":"code","outputId":"26ab2a8f-cd7a-4cf3-84fd-560263bff485","executionInfo":{"status":"ok","timestamp":1587108934569,"user_tz":360,"elapsed":21731,"user":{"displayName":"Elijah Cox","photoUrl":"","userId":"12779208509741799141"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["for i in political_info(\"https://joebiden.com/\", 'Joe Biden', '/gdrive/My Drive/LING/Final Project/Biden', n_topic=3):\n","  print(i)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[1, '\"biden\"', '\"loading\"', '\"text\"', '\"joebidencom\"', '\"candidate\"', '\"actblue\"', '\"contribution\"', '\"message\"']\n","[2, '\"joe\"', '\"biden\"', '\"president\"', '\"time\"', '\"year\"', '\"cancer\"', '\"american\"']\n","[3, '\"site\"', '\"biden\"', '\"information\"', '\"president\"', '\"use\"', '\"may\"', '\"content\"', '\"service\"']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LMOlbORIEaUY","colab_type":"code","outputId":"24bb0061-65db-45d4-c5e8-5bd2c63ecb24","executionInfo":{"status":"ok","timestamp":1587109257085,"user_tz":360,"elapsed":8627,"user":{"displayName":"Elijah Cox","photoUrl":"","userId":"12779208509741799141"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["for i in political_info(\"https://elizabethwarren.com/\", 'Elizabeth Warren', '/gdrive/My Drive/LING/Final Project/Warren', n_topic=4):\n","  print(i)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[1, '\"census\"', '\"u\"', '\"information\"', '\"respond\"', '\"answer\"', '\"law\"', '\"bureau\"', '\"2020\"']\n","[2, '\"closing\"', '\"temporarily\"', '\"production\"', '\"primary\"', '\"forced\"', '\"facility\"', '\"nonessential\"', '\"due\"']\n","[3, '\"warren\"', '\"elizabeth\"', '\"work\"', '\"crisis\"', '\"grassroots\"', '\"candidate\"', '\"people\"', '\"need\"']\n","[4, '\"information\"', '\"site\"', '\"may\"', '\"cooky\"', '\"collect\"', '\"campaign\"', '\"u\"', '\"provide\"']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rdPjtXfWEynW","colab_type":"code","outputId":"d65d60ba-57ce-424a-ef14-e95bf707a55b","executionInfo":{"status":"ok","timestamp":1587109602636,"user_tz":360,"elapsed":27039,"user":{"displayName":"Elijah Cox","photoUrl":"","userId":"12779208509741799141"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["for i in political_info(\"https://www.mikebloomberg.com/\", 'Mike Bloomberg', '/gdrive/My Drive/LING/Final Project/Bloomberg', n_topic=3):\n","  print(i)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[1, '\"information\"', '\"may\"', '\"city\"', '\"u\"', '\"school\"', '\"use\"', '\"new\"', '\"bloomberg\"']\n","[2, '\"bloomberg\"', '\"read\"', '\"city\"', '\"new\"', '\"mayor\"', '\"philanthropy\"', '\"public\"', '\"mike\"']\n","[3, '\"new\"', '\"bloomberg\"', '\"city\"', '\"2013\"', '\"administration\"', '\"million\"', '\"nyc\"']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"AqZTHzeIGy8Q","colab_type":"text"},"source":["Trump:\n","[1, '\"loading\"', '\"distancing\"', '\"vulnerable\"', '\"protocol\"', '\"adhere\"', '\"physical\"', '\"eg\"', '\"area\"']\n","[2, '\"coronavirus\"', '\"president\"', '\"april\"', '\"trump\"', '\"announced\"', '\"march\"', '\"new\"', '\"state\"']\n","[3, '\"tweet\"', '\"twitter\"', '\"add\"', '\"trump\"', '\"president\"', '\"america\"', '\"learn\"', '\"website\"']\n","[4, '\"afford\"', '\"phase\"', '\"httpwhitehousegovopeningamerica\"', '\"health\"', '\"mikepence\"', '\"help\"', '\"penny\"', '\"please\"']\n","[5, '\"trump\"', '\"contribution\"', '\"president\"', '\"committee\"', '\"america\"', '\"federal\"', '\"election\"', '\"j\"']\n","\n","Biden:\n","[1, '\"biden\"', '\"loading\"', '\"text\"', '\"joebidencom\"', '\"candidate\"', '\"actblue\"', '\"contribution\"', '\"message\"']\n","[2, '\"joe\"', '\"biden\"', '\"president\"', '\"time\"', '\"year\"', '\"cancer\"', '\"american\"']\n","[3, '\"site\"', '\"biden\"', '\"information\"', '\"president\"', '\"use\"', '\"may\"', '\"content\"', '\"service\"']\n","\n","Warren:\n","[1, '\"census\"', '\"u\"', '\"information\"', '\"respond\"', '\"answer\"', '\"law\"', '\"bureau\"', '\"2020\"']\n","[2, '\"closing\"', '\"temporarily\"', '\"production\"', '\"primary\"', '\"forced\"', '\"facility\"', '\"nonessential\"', '\"due\"']\n","[3, '\"warren\"', '\"elizabeth\"', '\"work\"', '\"crisis\"', '\"grassroots\"', '\"candidate\"', '\"people\"', '\"need\"']\n","[4, '\"information\"', '\"site\"', '\"may\"', '\"cooky\"', '\"collect\"', '\"campaign\"', '\"u\"', '\"provide\"']\n","\n","Bloomberg:\n","[1, '\"information\"', '\"may\"', '\"city\"', '\"u\"', '\"school\"', '\"use\"', '\"new\"', '\"bloomberg\"']\n","[2, '\"bloomberg\"', '\"read\"', '\"city\"', '\"new\"', '\"mayor\"', '\"philanthropy\"', '\"public\"', '\"mike\"']\n","[3, '\"new\"', '\"bloomberg\"', '\"city\"', '\"2013\"', '\"administration\"', '\"million\"', '\"nyc\"']"]},{"cell_type":"code","metadata":{"id":"n1MiBxU6FtTo","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}